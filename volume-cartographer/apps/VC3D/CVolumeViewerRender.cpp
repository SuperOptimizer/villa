#include "CVolumeViewer.hpp"
#include "ViewerManager.hpp"
#include "vc/ui/UDataManipulateUtils.hpp"

#include "VolumeViewerCmaps.hpp"

#include <iostream>
#include <QGraphicsView>
#include <QGraphicsScene>
#include <QDebug>
#include <QGraphicsPixmapItem>
#include <QGraphicsEllipseItem>
#include <QGraphicsItem>

#include "CVolumeViewerView.hpp"
#include "CSurfaceCollection.hpp"
#include "vc/ui/VCCollection.hpp"

#include "vc/core/types/Volume.hpp"
#include "vc/core/types/VolumePkg.hpp"
#include "vc/core/util/Surface.hpp"
#include "vc/core/util/QuadSurface.hpp"
#include "vc/core/util/PlaneSurface.hpp"
#include "vc/core/util/Compositing.hpp"

#include <omp.h>


#include <QPainter>
#include <optional>

#include <opencv2/imgproc.hpp>

#define COLOR_FOCUS QColor(50, 255, 215)

void CVolumeViewer::renderVisible(bool force)
{
    auto surf = _surf_weak.lock();
    if (surf && _surf_col) {
        auto currentSurface = _surf_col->surface(_surf_name);
        if (!currentSurface) {
            // Surface was cleared (e.g. during volume reload) without a change signal
            // reaching this viewer yet; drop the dangling pointer before rendering.
            _surf_weak.reset();
            surf.reset();
        }
    }

    if (!volume || !surf)
        return;

    QRectF bbox = fGraphicsView->mapToScene(fGraphicsView->viewport()->geometry()).boundingRect();

    if (!force && QRectF(curr_img_area).contains(bbox))
        return;


    curr_img_area = {static_cast<int>(bbox.left()),static_cast<int>(bbox.top()), static_cast<int>(bbox.width()), static_cast<int>(bbox.height())};

    cv::Mat img = render_area({curr_img_area.x(), curr_img_area.y(), curr_img_area.width(), curr_img_area.height()});

    QImage qimg = Mat2QImage(img);
    if (_overlayImageValid && !_overlayImage.isNull()) {
        qimg = qimg.convertToFormat(QImage::Format_RGBA8888);
        QPainter painter(&qimg);
        painter.setCompositionMode(QPainter::CompositionMode_SourceOver);
        painter.drawImage(0, 0, _overlayImage);
    }

    QPixmap pixmap = QPixmap::fromImage(qimg, fSkipImageFormatConv ? Qt::NoFormatConversion : Qt::AutoColor);

    // Add the QPixmap to the scene as a QGraphicsPixmapItem
    if (!fBaseImageItem)
        fBaseImageItem = fScene->addPixmap(pixmap);
    else
        fBaseImageItem->setPixmap(pixmap);

    if (!_center_marker) {
        _center_marker = fScene->addEllipse({-10,-10,20,20}, QPen(COLOR_FOCUS, 3, Qt::DashDotLine, Qt::RoundCap, Qt::RoundJoin));
        _center_marker->setZValue(11);
    }

    _center_marker->setParentItem(fBaseImageItem);

    fBaseImageItem->setOffset(curr_img_area.topLeft());
}


cv::Mat_<uint8_t> CVolumeViewer::render_composite(const cv::Rect &roi) {
    cv::Mat_<uint8_t> img;

    auto surf = _surf_weak.lock();
    if (!surf)
        return img;

    cv::Vec2f roi_c = {static_cast<float>(roi.x + roi.width / 2), static_cast<float>(roi.y + roi.height / 2)};
    cv::Vec3f ptr = surf->pointer();
    cv::Vec3f diff = {roi_c[0], roi_c[1], 0};
    surf->move(ptr, diff / _scale);
    _ptr = ptr;
    _vis_center = roi_c;

    // Check if we can reuse cached normals
    // Cache key: roi size, scale, ptr position, and surface instance
    // Note: z_off is NOT part of the cache key - normals don't depend on z_off,
    // and we apply the z offset ourselves after retrieving cached values
    bool cacheValid = (!_cachedNormals.empty() &&
                       _cachedNormalsSize == roi.size() &&
                       std::abs(_cachedNormalsScale - _scale) < 1e-6f &&
                       cv::norm(_cachedNormalsPtr - ptr) < 1e-6f &&
                       _cachedNormalsSurf.lock() == surf);

    cv::Mat_<cv::Vec3f> base_coords;
    cv::Mat_<cv::Vec3f> normals;

    if (cacheValid) {
        // Reuse cached coordinates and normals
        // Cached coords are at z_off=0, so apply current z_off if needed
        if (std::abs(_z_off - _cachedNormalsZOff) < 1e-6f) {
            // Same z_off, use cached coords directly
            base_coords = _cachedBaseCoords;
        } else {
            // Different z_off - apply offset along normals using work buffer
            const int h = _cachedBaseCoords.rows;
            const int w = _cachedBaseCoords.cols;

            // Reuse work buffer if size matches, otherwise reallocate
            if (_coordsWorkBuffer.rows != h || _coordsWorkBuffer.cols != w) {
                _coordsWorkBuffer.create(h, w);
            }

            const float z_delta = _z_off - _cachedNormalsZOff;
            #pragma omp parallel for collapse(2) schedule(static)
            for (int j = 0; j < h; ++j) {
                for (int i = 0; i < w; ++i) {
                    const cv::Vec3f& src = _cachedBaseCoords(j, i);
                    const cv::Vec3f& n = _cachedNormals(j, i);
                    if (std::isfinite(n[0]) && std::isfinite(n[1]) && std::isfinite(n[2])) {
                        _coordsWorkBuffer(j, i) = src + n * z_delta;
                    } else {
                        _coordsWorkBuffer(j, i) = src;
                    }
                }
            }
            base_coords = _coordsWorkBuffer;
        }
        normals = _cachedNormals;
    } else {
        // Generate coordinates and normals for base layer
        surf->gen(&base_coords, &normals, roi.size(), ptr, _scale,
                  {static_cast<float>(-roi.width / 2), static_cast<float>(-roi.height / 2), _z_off});

        // Cache for next render - gen() returns freshly allocated data, so we can
        // just copy the cv::Mat header (shallow copy) since we own the data
        _cachedBaseCoords = base_coords;
        _cachedNormals = normals;
        _cachedNormalsSize = roi.size();
        _cachedNormalsScale = _scale;
        _cachedNormalsPtr = ptr;
        _cachedNormalsZOff = _z_off;
        _cachedNormalsSurf = surf;
    }

    // Compute volume gradients if enabled (for PBR lighting from volume data)
    // Gradients are computed once at native surface resolution (raw point grid),
    // then warped to view resolution using the same transform as gen() uses for coords
    cv::Mat_<cv::Vec3f> lightingNormals = normals;  // Default to mesh normals
    if (_use_volume_gradients && _lighting_enabled) {
        auto* quadSurf = dynamic_cast<QuadSurface*>(surf.get());
        if (quadSurf) {
            // Compute native gradients once per surface
            if (_cachedNativeVolumeGradients.empty() || _cachedGradientsSurf.lock() != surf) {
                const cv::Mat_<cv::Vec3f>* rawPts = quadSurf->rawPointsPtr();
                _cachedNativeVolumeGradients = volume->computeGradients(*rawPts, _ds_scale, _ds_sd_idx);
                _cachedGradientsSurf = surf;
            }

            // Warp native gradients to view coords using same transform as gen()
            const cv::Vec2f surfScale = quadSurf->scale();
            const cv::Vec3f center = quadSurf->center();

            // Same calculation as gen(): ul = internal_loc(offset/scale + _center, ptr, _scale)
            const cv::Vec3f offset = {static_cast<float>(-roi.width / 2), static_cast<float>(-roi.height / 2), _z_off};
            const cv::Vec3f nominalOffset = offset / _scale + center;
            const cv::Vec3f ul = ptr + cv::Vec3f(nominalOffset[0] * surfScale[0], nominalOffset[1] * surfScale[1], nominalOffset[2]);

            const double sx = static_cast<double>(surfScale[0]) / static_cast<double>(_scale);
            const double sy = static_cast<double>(surfScale[1]) / static_cast<double>(_scale);
            const double ox = static_cast<double>(ul[0]);
            const double oy = static_cast<double>(ul[1]);

            // Map from raw grid coords to view coords
            std::array<cv::Point2f, 3> srcf = {
                cv::Point2f(static_cast<float>(ox), static_cast<float>(oy)),
                cv::Point2f(static_cast<float>(ox + roi.width * sx), static_cast<float>(oy)),
                cv::Point2f(static_cast<float>(ox), static_cast<float>(oy + roi.height * sy))
            };
            std::array<cv::Point2f, 3> dstf = {
                cv::Point2f(0.f, 0.f),
                cv::Point2f(static_cast<float>(roi.width), 0.f),
                cv::Point2f(0.f, static_cast<float>(roi.height))
            };

            cv::Mat A = cv::getAffineTransform(srcf.data(), dstf.data());
            cv::warpAffine(_cachedNativeVolumeGradients, lightingNormals, A, roi.size(),
                           cv::INTER_LINEAR, cv::BORDER_REPLICATE);
        }
    }

    // Determine the z range based on front and behind layers
    int z_start = _composite_reverse_direction ? -_composite_layers_behind : -_composite_layers_front;
    int z_end = _composite_reverse_direction ? _composite_layers_front : _composite_layers_behind;

    // Setup compositing parameters
    CompositeParams params;
    params.method = _composite_method;
    params.resolveMethodType();
    params.alphaMin = _composite_alpha_min / 255.0f;
    params.alphaMax = _composite_alpha_max / 255.0f;
    params.alphaOpacity = _composite_material / 255.0f;
    params.alphaCutoff = _composite_alpha_threshold / 10000.0f;
    params.blExtinction = _composite_bl_extinction;
    params.blEmission = _composite_bl_emission;
    params.blAmbient = _composite_bl_ambient;
    params.lightingEnabled = _lighting_enabled;
    params.lightAzimuth = _light_azimuth;
    params.lightElevation = _light_elevation;
    params.lightDiffuse = _light_diffuse;
    params.lightAmbient = _light_ambient;
    params.isoCutoff = static_cast<uint8_t>(_iso_cutoff);

    // Always use fast path (nearest neighbor, no mutex, specialized cache)
    volume->readComposite(
        img,
        base_coords * _ds_scale,
        lightingNormals,
        _ds_scale,  // z step per layer (in dataset coordinates)
        z_start, z_end,
        params,
        _ds_sd_idx
    );

    // Apply postprocessing
    if (!img.empty()) {
        // Stretch values to full range
        if (_postStretchValues) {
            double minVal, maxVal;
            cv::minMaxLoc(img, &minVal, &maxVal);
            if (maxVal > minVal) {
                img.convertTo(img, CV_8U, 255.0 / (maxVal - minVal), -minVal * 255.0 / (maxVal - minVal));
            }
        }

        // Remove small connected components
        if (_postRemoveSmallComponents && _postMinComponentSize > 1) {
            // Create binary mask of non-zero pixels
            cv::Mat_<uint8_t> binary;
            cv::threshold(img, binary, 0, 255, cv::THRESH_BINARY);

            // Find connected components
            cv::Mat labels, stats, centroids;
            int numComponents = cv::connectedComponentsWithStats(binary, labels, stats, centroids, 8, CV_32S);

            // Create mask of components to keep (those >= min size)
            cv::Mat_<uint8_t> keepMask = cv::Mat_<uint8_t>::zeros(img.size());
            for (int i = 1; i < numComponents; i++) {  // Start from 1 to skip background
                int area = stats.at<int>(i, cv::CC_STAT_AREA);
                if (area >= _postMinComponentSize) {
                    keepMask.setTo(255, labels == i);
                }
            }

            // Apply mask to original image
            cv::Mat_<uint8_t> filtered;
            img.copyTo(filtered, keepMask);
            img = filtered;
        }
    }

    return img;
}

cv::Mat_<uint8_t> CVolumeViewer::renderCompositeForSurface(const std::shared_ptr<QuadSurface>& surface, cv::Size outputSize)
{
    if (!surface || !_composite_enabled || !volume) {
        return cv::Mat_<uint8_t>();
    }

    // Save current state
    float oldScale = _scale;
    cv::Vec2f oldVisCenter = _vis_center;
    auto oldSurf = _surf_weak.lock();
    float oldZOff = _z_off;
    cv::Vec3f oldPtr = _ptr;
    float oldDsScale = _ds_scale;
    int oldDsSdIdx = _ds_sd_idx;

    // Render at 1:1 with the surface's internal grid (raw points size)
    // Use surface's scale so that gen() computes sx = _scale/_scale = 1.0,
    // sampling 1:1 from the raw points grid
    cv::Size rawPointsSize = surface->rawPointsPtr()->size();
    float surfScale = surface->_scale[0];

    std::cout << "[renderCompositeForSurface] outputSize: " << outputSize.width << "x" << outputSize.height
              << ", rawPointsSize: " << rawPointsSize.width << "x" << rawPointsSize.height
              << ", surface->_scale: " << surface->_scale[0] << "x" << surface->_scale[1] << "\n";

    _surf_weak = surface;
    _scale = surfScale;  // Use surface's scale so gen() samples 1:1 from raw points
    _z_off = 0.0f;

    recalcScales();

    std::cout << "[renderCompositeForSurface] after recalcScales: _scale=" << _scale
              << ", _ds_scale=" << _ds_scale << ", _ds_sd_idx=" << _ds_sd_idx << "\n";

    _ptr = surface->pointer();
    // Use raw points size for the ROI so we cover the whole surface
    cv::Rect roi(-rawPointsSize.width/2, -rawPointsSize.height/2,
                 rawPointsSize.width, rawPointsSize.height);

    _vis_center = cv::Vec2f(0, 0);

    cv::Mat_<uint8_t> result = render_composite(roi);

    std::cout << "[renderCompositeForSurface] result size: " << result.cols << "x" << result.rows << "\n";

    // Resize to requested output size if different
    if (result.size() != outputSize) {
        std::cout << "[renderCompositeForSurface] resizing from " << result.cols << "x" << result.rows
                  << " to " << outputSize.width << "x" << outputSize.height << "\n";
        cv::resize(result, result, outputSize, 0, 0, cv::INTER_LINEAR);
    }

    _surf_weak = oldSurf;
    _scale = oldScale;
    _vis_center = oldVisCenter;
    _z_off = oldZOff;
    _ptr = oldPtr;
    _ds_scale = oldDsScale;
    _ds_sd_idx = oldDsSdIdx;

    return result;
}


cv::Mat CVolumeViewer::render_area(const cv::Rect &roi)
{
    auto surf = _surf_weak.lock();
    if (!surf)
        return cv::Mat();

    cv::Mat_<cv::Vec3f> coords;
    cv::Mat_<uint8_t> baseGray;
    const int baseWindowLowInt = static_cast<int>(std::clamp(_baseWindowLow, 0.0f, 255.0f));
    const int baseWindowHighInt = static_cast<int>(
        std::clamp(_baseWindowHigh, static_cast<float>(baseWindowLowInt + 1), 255.0f));
    const float baseWindowSpan = std::max(1.0f, static_cast<float>(baseWindowHighInt - baseWindowLowInt));

    _overlayImageValid = false;
    _overlayImage = QImage();

    const QRect roiRect(roi.x, roi.y, roi.width, roi.height);

    const bool useComposite = (_surf_name == "segmentation" && _composite_enabled &&
                               (_composite_layers_front > 0 || _composite_layers_behind > 0));

    cv::Mat baseColor;

    // Check if this is a plane surface that should use plane composite rendering
    PlaneSurface* plane = dynamic_cast<PlaneSurface*>(surf.get());
    const bool usePlaneComposite = (plane != nullptr && _plane_composite_enabled &&
                                    (_plane_composite_layers_front > 0 || _plane_composite_layers_behind > 0));

    if (useComposite) {
        baseGray = render_composite(roi);
    } else if (usePlaneComposite) {
        // Plane composite: generate coords first, then composite along plane normal
        surf->gen(&coords, nullptr, roi.size(), cv::Vec3f(0, 0, 0), _scale, {static_cast<float>(roi.x), static_cast<float>(roi.y), _z_off});
        baseGray = render_composite_plane(roi, coords, plane->normal(cv::Vec3f(0, 0, 0)));
    } else {
        if (plane) {
            surf->gen(&coords, nullptr, roi.size(), cv::Vec3f(0, 0, 0), _scale, {static_cast<float>(roi.x), static_cast<float>(roi.y), _z_off});

        } else {
            cv::Vec2f roi_c = {roi.x + roi.width / 2.0f, roi.y + roi.height / 2.0f};
            _ptr = surf->pointer();
            cv::Vec3f diff = {roi_c[0], roi_c[1], 0};
            surf->move(_ptr, diff / _scale);
            _vis_center = roi_c;

            surf->gen(&coords, nullptr, roi.size(), _ptr, _scale, {-roi.width / 2.0f, -roi.height / 2.0f, _z_off});
        }

        if (!volume) {
            return cv::Mat();
        }
        volume->readInterpolated(baseGray, coords * _ds_scale, _interpolationMethod, _ds_sd_idx);
    }

    if (baseGray.empty()) {
        return cv::Mat();
    }

    // Apply ISO cutoff - zero out values below threshold
    if (_iso_cutoff > 0 && !baseGray.empty()) {
        cv::threshold(baseGray, baseGray, _iso_cutoff - 1, 0, cv::THRESH_TOZERO);
    }

    cv::Mat baseProcessed;

    // Apply stretching if enabled
    if (_stretchValues) {
        double minVal, maxVal;
        cv::minMaxLoc(baseGray, &minVal, &maxVal);
        const double range = std::max(1.0, maxVal - minVal);

        cv::Mat baseFloat;
        baseGray.convertTo(baseFloat, CV_32F);
        baseFloat -= static_cast<float>(minVal);
        baseFloat /= static_cast<float>(range);
        baseFloat.convertTo(baseProcessed, CV_8U, 255.0f);
    } else {
        // Apply window/level transformation
        cv::Mat baseFloat;
        baseGray.convertTo(baseFloat, CV_32F);
        baseFloat -= static_cast<float>(baseWindowLowInt);
        baseFloat /= baseWindowSpan;
        cv::max(baseFloat, 0.0f, baseFloat);
        cv::min(baseFloat, 1.0f, baseFloat);
        baseFloat.convertTo(baseProcessed, CV_8U, 255.0f);
    }

    // Apply colormap if specified
    if (!_baseColormapId.empty()) {
        const auto& spec = volume_viewer_cmaps::resolve(_baseColormapId);
        baseColor = volume_viewer_cmaps::makeColors(baseProcessed, spec);
    } else {
        // Convert to BGR
        if (baseProcessed.channels() == 1) {
            cv::cvtColor(baseProcessed, baseColor, cv::COLOR_GRAY2BGR);
        } else {
            baseColor = baseProcessed.clone();
        }
    }

    if (_overlayVolume && _overlayOpacity > 0.0f) {
        if (coords.empty()) {
            if (auto* plane = dynamic_cast<PlaneSurface*>(surf.get())) {
                surf->gen(&coords, nullptr, roi.size(), cv::Vec3f(0, 0, 0), _scale, {static_cast<float>(roi.x), static_cast<float>(roi.y), _z_off});
            } else {
                cv::Vec2f roi_c = {roi.x + roi.width / 2.0f, roi.y + roi.height / 2.0f};
                _ptr = surf->pointer();
                cv::Vec3f diff = {roi_c[0], roi_c[1], 0};
                surf->move(_ptr, diff / _scale);
                _vis_center = roi_c;
                surf->gen(&coords, nullptr, roi.size(), _ptr, _scale, {-roi.width / 2.0f, -roi.height / 2.0f, _z_off});
            }
        }

        if (!coords.empty()) {
            int overlayIdx = 0;
            float overlayScale = 1.0f;
            if (_overlayVolume->numScales() > 0) {
                overlayIdx = std::min<int>(_ds_sd_idx, static_cast<int>(_overlayVolume->numScales()) - 1);
                overlayScale = std::pow(2.0f, -overlayIdx);
            }

            cv::Mat_<uint8_t> overlayValues;
            _overlayVolume->readInterpolated(overlayValues, coords * overlayScale, InterpolationMethod::Nearest, overlayIdx);

            if (!overlayValues.empty()) {
                const int windowLow = static_cast<int>(std::clamp(_overlayWindowLow, 0.0f, 255.0f));
                const int windowHigh = static_cast<int>(std::clamp(_overlayWindowHigh, static_cast<float>(windowLow + 1), 255.0f));

                cv::Mat activeMask;
                cv::compare(overlayValues, windowLow, activeMask, cv::CmpTypes::CMP_GE);

                if (cv::countNonZero(activeMask) > 0) {
                    cv::Mat overlayScaled;
                    overlayValues.convertTo(overlayScaled, CV_32F);
                    overlayScaled -= static_cast<float>(windowLow);
                    overlayScaled.setTo(0.0f, overlayScaled < 0.0f);
                    const float windowSpan = std::max(1.0f, static_cast<float>(windowHigh - windowLow));
                    overlayScaled /= windowSpan;
                    cv::threshold(overlayScaled, overlayScaled, 1.0f, 1.0f, cv::THRESH_TRUNC);

                    cv::Mat overlayColorInput;
                    overlayScaled.convertTo(overlayColorInput, CV_8U, 255.0f);

                    const auto& spec = volume_viewer_cmaps::resolve(_overlayColormapId);
                    cv::Mat overlayColor = volume_viewer_cmaps::makeColors(overlayColorInput, spec);

                    if (!overlayColor.empty()) {
                        cv::Mat inactiveMask;
                        cv::bitwise_not(activeMask, inactiveMask);
                        overlayColor.setTo(cv::Scalar(0, 0, 0), inactiveMask);

                        cv::Mat overlayBGRA;
                        cv::cvtColor(overlayColor, overlayBGRA, cv::COLOR_BGR2BGRA);

                        std::vector<cv::Mat> channels;
                        cv::split(overlayBGRA, channels);
                        const uchar alphaValue = static_cast<uchar>(std::round(std::clamp(_overlayOpacity, 0.0f, 1.0f) * 255.0f));
                        channels[3].setTo(alphaValue, activeMask);
                        channels[3].setTo(0, inactiveMask);
                        cv::merge(channels, overlayBGRA);

                        cv::cvtColor(overlayBGRA, overlayBGRA, cv::COLOR_BGRA2RGBA);
                        QImage overlayImage(overlayBGRA.data, overlayBGRA.cols, overlayBGRA.rows, overlayBGRA.step, QImage::Format_RGBA8888);
                        _overlayImage = overlayImage.copy();
                        _overlayImageValid = true;
                    }
                }
            }
        }
    }

    // Surface overlap detection using SurfacePatchIndex (multi-surface with colors)
    // Only process in segmentation viewer - plane views don't need surface overlays
    if (_surf_name == "segmentation" && _surfaceOverlayEnabled && !_surfaceOverlays.empty() && _surf_col && !baseColor.empty()) {
        auto* patchIndex = _viewerManager ? _viewerManager->surfacePatchIndex() : nullptr;
        if (patchIndex) {
            // Use subsampling for many surfaces (conservative 2x stride)
            const int stride = (_surfaceOverlays.size() > 50) ? 2 : 1;
            const int sampledRows = (coords.rows + stride - 1) / stride;
            const int sampledCols = (coords.cols + stride - 1) / stride;

            // Compute viewport bounding box for early culling (sparse sampling)
            cv::Vec3f viewMin(std::numeric_limits<float>::max(), std::numeric_limits<float>::max(), std::numeric_limits<float>::max());
            cv::Vec3f viewMax(-std::numeric_limits<float>::max(), -std::numeric_limits<float>::max(), -std::numeric_limits<float>::max());
            for (int y = 0; y < coords.rows; y += 10) {
                for (int x = 0; x < coords.cols; x += 10) {
                    const cv::Vec3f& p = coords(y, x);
                    if (p[0] >= 0) {
                        for (int i = 0; i < 3; ++i) {
                            viewMin[i] = std::min(viewMin[i], p[i]);
                            viewMax[i] = std::max(viewMax[i], p[i]);
                        }
                    }
                }
            }
            // Expand by threshold for overlap detection
            viewMin -= cv::Vec3f(_surfaceOverlapThreshold, _surfaceOverlapThreshold, _surfaceOverlapThreshold);
            viewMax += cv::Vec3f(_surfaceOverlapThreshold, _surfaceOverlapThreshold, _surfaceOverlapThreshold);

            // Track overlay colors and counts at sampled resolution
            cv::Mat_<cv::Vec3f> overlayColorSum(sampledRows, sampledCols, cv::Vec3f(0, 0, 0));
            cv::Mat_<uint8_t> overlapCount(sampledRows, sampledCols, uint8_t(0));

            // Thread-local accumulators to avoid critical section
            const int num_threads = omp_get_max_threads();
            std::vector<cv::Mat_<cv::Vec3f>> thread_colorSum(num_threads);
            std::vector<cv::Mat_<uint8_t>> thread_count(num_threads);
            for (int t = 0; t < num_threads; ++t) {
                thread_colorSum[t] = cv::Mat_<cv::Vec3f>(sampledRows, sampledCols, cv::Vec3f(0, 0, 0));
                thread_count[t] = cv::Mat_<uint8_t>(sampledRows, sampledCols, uint8_t(0));
            }

            for (const auto& [overlayName, overlayColor] : _surfaceOverlays) {
                auto overlaySurf = _surf_col->surface(overlayName);
                auto overlayQuad = std::dynamic_pointer_cast<QuadSurface>(overlaySurf);
                if (!overlayQuad || overlaySurf == surf) {
                    continue;  // Skip self or invalid surfaces
                }

                // Bounding box culling: skip surfaces that can't intersect viewport
                // Use cached bbox - O(1) for surfaces loaded from disk
                const Rect3D surfBBox = overlayQuad->bbox();
                const cv::Vec3f& surfMin = surfBBox.low;
                const cv::Vec3f& surfMax = surfBBox.high;

                // Skip if bbox is invalid (uninitialized surface)
                if (surfMin[0] < 0) {
                    continue;
                }

                bool canIntersect = true;
                for (int i = 0; i < 3; ++i) {
                    if (surfMin[i] > viewMax[i] || surfMax[i] < viewMin[i]) {
                        canIntersect = false;
                        break;
                    }
                }
                if (!canIntersect) {
                    continue;
                }

                const cv::Vec3f colorVec(overlayColor[0], overlayColor[1], overlayColor[2]);

                // For each sampled base surface point, query distance to this overlay surface
                #pragma omp parallel for collapse(2) schedule(static)
                for (int sy = 0; sy < sampledRows; ++sy) {
                    for (int sx = 0; sx < sampledCols; ++sx) {
                        const int y = sy * stride;
                        const int x = sx * stride;
                        if (y >= coords.rows || x >= coords.cols) continue;

                        const cv::Vec3f& basePos = coords(y, x);
                        if (basePos[0] >= 0) {
                            auto result = patchIndex->locate(basePos, _surfaceOverlapThreshold, overlayQuad);
                            if (result && result->distance < _surfaceOverlapThreshold) {
                                const int tid = omp_get_thread_num();
                                thread_colorSum[tid](sy, sx) += colorVec;
                                thread_count[tid](sy, sx)++;
                            }
                        }
                    }
                }
            }

            // Merge thread-local accumulators
            for (int t = 0; t < num_threads; ++t) {
                overlayColorSum += thread_colorSum[t];
                for (int sy = 0; sy < sampledRows; ++sy) {
                    for (int sx = 0; sx < sampledCols; ++sx) {
                        overlapCount(sy, sx) += thread_count[t](sy, sx);
                    }
                }
            }

            // Blend averaged overlay colors where surfaces overlap
            const float blendFactor = 0.5f;
            for (int y = 0; y < baseColor.rows; ++y) {
                for (int x = 0; x < baseColor.cols; ++x) {
                    const int sy = y / stride;
                    const int sx = x / stride;
                    if (sy < sampledRows && sx < sampledCols && overlapCount(sy, sx) > 0) {
                        cv::Vec3b& pixel = baseColor.at<cv::Vec3b>(y, x);
                        cv::Vec3f avgColor = overlayColorSum(sy, sx) / static_cast<float>(overlapCount(sy, sx));
                        pixel = cv::Vec3b(
                            static_cast<uint8_t>(pixel[0] * (1.0f - blendFactor) + avgColor[0] * blendFactor),
                            static_cast<uint8_t>(pixel[1] * (1.0f - blendFactor) + avgColor[1] * blendFactor),
                            static_cast<uint8_t>(pixel[2] * (1.0f - blendFactor) + avgColor[2] * blendFactor)
                        );
                    }
                }
            }
        }
    }

    return baseColor;
}

void CVolumeViewer::setBaseColormap(const std::string& colormapId)
{
    if (_baseColormapId == colormapId) {
        return;
    }
    _baseColormapId = colormapId;
    if (volume) {
        renderVisible(true);
    }
}

void CVolumeViewer::setStretchValues(bool enabled)
{
    if (_stretchValues == enabled) {
        return;
    }
    _stretchValues = enabled;
    if (volume) {
        renderVisible(true);
    }
}

void CVolumeViewer::setSurfaceOverlayEnabled(bool enabled)
{
    if (_surfaceOverlayEnabled == enabled) {
        return;
    }
    _surfaceOverlayEnabled = enabled;
    if (volume) {
        renderVisible(true);
    }
}

void CVolumeViewer::setSurfaceOverlays(const std::map<std::string, cv::Vec3b>& overlays)
{
    if (_surfaceOverlays == overlays) {
        return;
    }
    _surfaceOverlays = overlays;
    if (volume && _surfaceOverlayEnabled) {
        renderVisible(true);
    }
}

void CVolumeViewer::setSurfaceOverlapThreshold(float threshold)
{
    threshold = std::max(0.1f, threshold);
    if (std::abs(threshold - _surfaceOverlapThreshold) < 1e-6f) {
        return;
    }
    _surfaceOverlapThreshold = threshold;
    if (volume && _surfaceOverlayEnabled) {
        renderVisible(true);
    }
}

void CVolumeViewer::setPlaneCompositeEnabled(bool enabled)
{
    if (_plane_composite_enabled == enabled) {
        return;
    }
    _plane_composite_enabled = enabled;
    if (volume) {
        renderVisible(true);
    }
}

void CVolumeViewer::setPlaneCompositeLayers(int front, int behind)
{
    front = std::max(0, front);
    behind = std::max(0, behind);
    if (_plane_composite_layers_front == front && _plane_composite_layers_behind == behind) {
        return;
    }
    _plane_composite_layers_front = front;
    _plane_composite_layers_behind = behind;
    if (volume && _plane_composite_enabled) {
        renderVisible(true);
    }
}

cv::Mat_<uint8_t> CVolumeViewer::render_composite_plane(const cv::Rect &roi, const cv::Mat_<cv::Vec3f> &coords, const cv::Vec3f &planeNormal)
{
    cv::Mat_<uint8_t> img;

    if (coords.empty() || !volume) {
        return img;
    }

    // Determine z range based on front and behind layers
    // For planes, "front" means along the positive normal direction
    int z_start = _composite_reverse_direction ? -_plane_composite_layers_behind : -_plane_composite_layers_front;
    int z_end = _composite_reverse_direction ? _plane_composite_layers_front : _plane_composite_layers_behind;

    // Setup compositing parameters (reuse the same parameters as segmentation composite)
    CompositeParams params;
    params.method = _composite_method;
    params.resolveMethodType();
    params.alphaMin = _composite_alpha_min / 255.0f;
    params.alphaMax = _composite_alpha_max / 255.0f;
    params.alphaOpacity = _composite_material / 255.0f;
    params.alphaCutoff = _composite_alpha_threshold / 10000.0f;
    params.blExtinction = _composite_bl_extinction;
    params.blEmission = _composite_bl_emission;
    params.blAmbient = _composite_bl_ambient;
    params.lightingEnabled = _lighting_enabled;
    params.lightAzimuth = _light_azimuth;
    params.lightElevation = _light_elevation;
    params.lightDiffuse = _light_diffuse;
    params.lightAmbient = _light_ambient;
    params.isoCutoff = static_cast<uint8_t>(_iso_cutoff);

    // Always use fast path with constant normal (nearest neighbor, no mutex)
    volume->readCompositeConstantNormal(
        img,
        coords * _ds_scale,
        planeNormal,  // Single constant normal for all pixels
        _ds_scale,    // z step per layer (in dataset coordinates)
        z_start, z_end,
        params,
        _ds_sd_idx
    );

    return img;
}